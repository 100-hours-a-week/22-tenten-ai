import logging
import os
from datetime import datetime
from schemas.bot_posts_schema import BotPostsRequest, BotPostsResponse, BotPostResponseData, UserInfoResponse
from core.prompt_templates.bot_posts_prompt import BotPostsPrompt
from utils.error_handler import InvalidQueryParameterError, InternalServerError

from dotenv import load_dotenv
from langfuse import Langfuse
from langchain_core.messages import BaseMessage
from langgraph.graph import StateGraph, END

import re
from utils.logger import log_inference_to_langfuse
from typing import Literal, TypedDict, Any

class GraphState(TypedDict):
    """
    Represents the state of our graph.

    Attributes:
        posts: The initial posts request data.
        retry_count: How many times we've retried.
        original_content: The content generated by the AI model.
        cleaned_content: The content after cleaning.
        evaluation_status: The evaluation status of the cleaned content (e.g., "success", "empty", "low_quality").
        error: Any error encountered during the process.
        messages: The list of messages sent to the AI model.
        prompt_client: The prompt client used for the AI model.
        trace: The Langfuse trace object for the entire graph execution.
    """
    posts: BotPostsRequest
    retry_count: int
    original_content: str
    cleaned_content: str
    evaluation_status: Literal["success", "empty", "low_quality"]
    error: str
    messages: list[BaseMessage]
    prompt_client: Any
    trace: Any

class BotPostsService:
    def __init__(self, app):
        self.logger = logging.getLogger(__name__)
        # FastAPI app의 state에서 model 싱글턴 인스턴스를 받아옴
        self.model = app.state.model
        self.mode = self.model.mode
        print(f"MODE : {self.mode}")
        
        # Langfuse 초기화
        self.langfuse = Langfuse(
            secret_key=os.getenv('LANGFUSE_SECRET_KEY'),
            public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),
            host=os.getenv('LANGFUSE_HOST')
        )

        # Langgraph 빌드
        workflow = StateGraph(GraphState)

        # 노드 추가
        workflow.add_node("generate_post", self._generate_post_node)
        workflow.add_node("clean_and_evaluate", self._clean_and_evaluate_node)
        workflow.add_node("check_retry_conditions", self._check_retry_conditions_node)

        # 에지 추가
        workflow.set_entry_point("generate_post")
        workflow.add_edge("generate_post", "clean_and_evaluate")
        workflow.add_conditional_edges(
            "clean_and_evaluate",
            self._decide_on_evaluation,
            {
                "continue": "check_retry_conditions",
                "end": END
            }
        )
        workflow.add_conditional_edges(
            "check_retry_conditions",
            self._should_continue_retry,
            {
                "retry": "generate_post",
                "end_failure": END
            }
        )

        self.app_graph = workflow.compile()

    def clean_response(self, text):
        # Remove everything before the first colon, inclusive
        if ':' in text:
            text = text.split(':', 1)[1]
        # Remove content inside square brackets including the brackets
        text = re.sub(r'\[.*?\]', '', text)
        # Replace multiple spaces with a single space
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def _decide_on_evaluation(self, state: GraphState) -> Literal["continue", "end"]:
        if state["evaluation_status"] == "success":
            return "end"
        else:
            return "continue"

    def _should_continue_retry(self, state: GraphState) -> Literal["retry", "end_failure"]:
        if state["retry_count"] < 3:
            return "retry"
        else:
            return "end_failure"

    async def _generate_post_node(self, state: GraphState) -> GraphState:
        current_posts = state["posts"]
        main_trace = state["trace"]

        # 노드 실행을 위한 스팬 생성 (with 문 제거)
        node_span = main_trace.span(
            name=f"generate_post_node_attempt_{state['retry_count']}",
            metadata={
                "board_type": current_posts.board_type,
                "post_count": len(current_posts.posts),
                "retry_attempt": state["retry_count"]
            },
            input=current_posts.posts,
            environment=self.mode
        )

        try:
            bot_post_prompt = BotPostsPrompt()
            prompt_client, messages = bot_post_prompt.json_to_messages(current_posts.posts, self.mode)
            state["messages"] = messages
            state["prompt_client"] = prompt_client

            log_model_parameters = {
                "temperature": self.model.loader.temperature,
                "top_p": self.model.loader.top_p,
                "max_tokens": self.model.loader.max_tokens,
                "stop": self.model.loader.stop,
            }
            
            # Generation 시작 시간
            start_time = datetime.now()
            model_response = self.model.get_response(
                messages, trace=node_span, start_time=start_time, prompt=prompt_client, name="generate_bot_post", adapter_type="social_bot"
            )
            end_time = datetime.now()

            original_content = model_response.get("content", "")

            log_inference_to_langfuse(
                trace=node_span,
                name="generate_bot_post_original",
                prompt=prompt_client,
                messages=messages,
                content=original_content,
                model_name=self.model.loader.model_path,
                model_parameters=log_model_parameters,
                input_tokens=None,
                output_tokens=None,
                inference_time=(end_time - start_time).total_seconds(),
                start_time=start_time,
                end_time=end_time,
                error=None
            )
            print(f"content : {original_content}")
            print(f"inference_time : {(end_time - start_time).total_seconds()}")

            state["original_content"] = original_content
            state["error"] = ""

        except Exception as e:
            self.logger.error(f"Error generating bot post in node: {e}", exc_info=True)
            state["error"] = str(e)
            node_span.update(
                status="error",
                error=str(e),
                metadata={"error_type": type(e).__name__}
            )
            state["original_content"] = ""
        finally:
            node_span.end()

        return state

    async def _clean_and_evaluate_node(self, state: GraphState) -> GraphState:
        original_content = state["original_content"]
        main_trace = state["trace"]
        messages = state["messages"]
        prompt_client = state["prompt_client"]

        # 노드 실행을 위한 스팬 생성 (with 문 제거)
        node_span = main_trace.span(name=f"clean_and_evaluate_node_attempt_{state['retry_count']}")
        try:
            log_model_parameters = {
                "temperature": self.model.loader.temperature,
                "top_p": self.model.loader.top_p,
                "max_tokens": self.model.loader.max_tokens,
                "stop": self.model.loader.stop,
            }

            start_time = datetime.now()
            content = self.clean_response(original_content)
            end_time = datetime.now()

            log_inference_to_langfuse(
                trace=node_span,
                name="generate_bot_post_cleaned",
                prompt=prompt_client,
                messages=messages,
                content=content,
                model_name=self.model.loader.model_path,
                model_parameters=log_model_parameters,
                input_tokens=None,
                output_tokens=None,
                inference_time=(end_time - start_time).total_seconds(),
                start_time=start_time,
                end_time=end_time,
                error=None
            )

            print(f"cleaned content : {content}")
            print(f"inference_time : {(end_time - start_time).total_seconds()}")

            if not content.strip():
                state["evaluation_status"] = "empty"
            else:
                state["evaluation_status"] = "success"

            state["cleaned_content"] = content
        except Exception as e:
            self.logger.error(f"Error cleaning and evaluating in node: {e}", exc_info=True)
            state["error"] = str(e)
            node_span.update(
                status="error",
                error=str(e),
                metadata={"error_type": type(e).__name__}
            )
            state["evaluation_status"] = "error"
        finally:
            node_span.end()
        return state

    async def _check_retry_conditions_node(self, state: GraphState) -> GraphState:
        state["retry_count"] += 1
        main_trace = state["trace"]
        return state

    async def generate_bot_post(self, request: BotPostsRequest) -> BotPostsResponse:
        """
        소셜봇 게시글을 생성하는 서비스
        Args:
            posts: 최근 5개의 게시글 정보
        Returns:
            생성된 소셜봇의 게시글
        Raises:
            InvalidQueryParameterError: posts 개수가 5개 미만인 경우
            InternalServerError: AI 서버 호출 실패 등 내부 오류 발생 시
        """
        # 400 error : 게시글 개수 검증
        if len(request.posts) < 5:
            raise InvalidQueryParameterError()

        # Langgraph 실행을 위한 메인 Langfuse 트레이스 시작
        main_trace = self.langfuse.trace(
            name="bot_posts_generation_langgraph_flow",
            metadata={
                "board_type": request.board_type,
                "initial_post_count": len(request.posts)
            },
            input=request.posts,
            environment=self.mode
        )

        initial_state: GraphState = {
            "posts": request,
            "retry_count": 0,
            "original_content": "",
            "cleaned_content": "",
            "evaluation_status": "empty",
            "error": "",
            "messages": [],
            "prompt_client": None,
            "trace": main_trace
        }

        try:
            final_state = await self.app_graph.ainvoke(initial_state)

            # 최종 결과 기록 및 메인 트레이스 업데이트
            main_trace.update(output=final_state["cleaned_content"])
            if final_state["evaluation_status"] == "success":
                main_trace.update(status="success")
            else:
                main_trace.update(
                    status="error",
                    error=final_state["error"] if final_state["error"] else "Failed to generate valid post after retries.",
                    metadata={
                        "final_retry_count": final_state["retry_count"],
                        "final_evaluation_status": final_state["evaluation_status"]
                    }
                )

            if final_state["evaluation_status"] == "success":
                bot_post_prompt = BotPostsPrompt()
                bot_user = bot_post_prompt.get_bot_user_info()
                data = BotPostResponseData(
                    board_type=request.board_type,
                    user=UserInfoResponse(**bot_user),
                    content=final_state["cleaned_content"]
                )
                return BotPostsResponse(
                    message="소셜봇이 게시물을 작성했습니다.",
                    data=data
                )
            else:
                self.logger.error(f"Failed to generate valid bot post after multiple retries. Last error: {final_state['error']}", exc_info=True)
                raise InternalServerError(
                    detail="Failed to generate bot post after multiple retries."
                )

        except InvalidQueryParameterError:
            # 400 에러는 그대로 상위로 전달, 메인 트레이스에 오류 기록
            if main_trace:
                main_trace.update(
                    status="error",
                    error="InvalidQueryParameterError",
                    metadata={"error_type": "InvalidQueryParameterError"}
                )
            raise

        except Exception as e:
            self.logger.error(f"Error during Langgraph execution: {e}", exc_info=True)
            # 예외 발생 시 메인 트레이스 업데이트
            if main_trace:
                main_trace.update(
                    status="error",
                    error=str(e),
                    metadata={"error_type": type(e).__name__}
                )
            raise InternalServerError()
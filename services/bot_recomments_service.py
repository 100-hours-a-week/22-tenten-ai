import logging
import os
from schemas.bot_recomments_schema import BotRecommentsRequest, BotRecommentsResponse, BotRecommentResponseData, UserInfoResponse
from core.prompt_templates.bot_recomments_prompt import BotRecommentsPrompt
from utils.error_handler import InvalidQueryParameterError, InternalServerError

from datetime import datetime
from dotenv import load_dotenv
from langfuse import Langfuse

import re
from utils.logger import log_inference_to_langfuse
from typing import Literal, TypedDict, Any
from langchain_core.messages import BaseMessage
from langgraph.graph import StateGraph, END


class GraphState(TypedDict):
    """
    Represents the state of our graph.

    Attributes:
        request: The initial BotRecommentsRequest data.
        retry_count: How many times we've retried.
        original_content: The content generated by the AI model.
        cleaned_content: The content after cleaning.
        evaluation_status: The evaluation status of the cleaned content (e.g., "success", "empty", "low_quality").
        error: Any error encountered during the process.
        messages: The list of messages sent to the AI model.
        prompt_client: The prompt client used for the AI model.
        trace: The Langfuse trace object for the entire graph execution.
    """
    request: BotRecommentsRequest
    retry_count: int
    original_content: str
    cleaned_content: str
    evaluation_status: Literal["success", "empty", "low_quality"]
    error: str
    messages: list[BaseMessage]
    prompt_client: Any
    trace: Any # LangfuseTrace 또는 LangfuseSpan 타입으로 사용될 수 있음


class BotRecommentsService:
    def __init__(self, app):
        self.logger = logging.getLogger(__name__)
        # FastAPI app의 state에서 model 싱글턴 인스턴스를 받아옴
        self.model = app.state.model
        self.mode = self.model.mode
        print(f"MODE : {self.mode}")

        # Langfuse 초기화
        if os.environ.get("LLM_MODE") == "api-prod":
            load_dotenv(dotenv_path='/secrets/env')
        else:
            load_dotenv(override=True)

        self.langfuse = Langfuse(
            secret_key=os.getenv('LANGFUSE_SECRET_KEY'),
            public_key=os.getenv('LANGFUSE_PUBLIC_KEY'),
            host=os.getenv('LANGFUSE_HOST')
        )

        # Langgraph 빌드
        workflow = StateGraph(GraphState)

        # 노드 추가
        workflow.add_node("generate_recomment", self._generate_recomment_node)
        workflow.add_node("clean_and_evaluate", self._clean_and_evaluate_node)
        workflow.add_node("check_retry_conditions", self._check_retry_conditions_node)

        # 에지 추가
        workflow.set_entry_point("generate_recomment")
        workflow.add_edge("generate_recomment", "clean_and_evaluate")
        workflow.add_conditional_edges(
            "clean_and_evaluate",
            self._decide_on_evaluation,
            {
                "continue": "check_retry_conditions",
                "end": END
            }
        )
        workflow.add_conditional_edges(
            "check_retry_conditions",
            self._should_continue_retry,
            {
                "retry": "generate_recomment",
                "end_failure": END
            }
        )

        self.app_graph = workflow.compile()

    def clean_response(self, text):
        
        if ':' in text:
            text = text.split(':', 1)[1]
        
        text = re.sub(r'\[.*?\]', '', text)
        
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def _decide_on_evaluation(self, state: GraphState) -> Literal["continue", "end"]:
        if state["evaluation_status"] == "success":
            return "end"
        else:
            return "continue"

    def _should_continue_retry(self, state: GraphState) -> Literal["retry", "end_failure"]:
        if state["retry_count"] < 3:
            return "retry"
        else:
            return "end_failure"

    async def _generate_recomment_node(self, state: GraphState) -> GraphState:
        current_request = state["request"]
        main_trace = state["trace"]

        # 노드 실행을 위한 스팬 생성
        node_span = main_trace.span(
            name=f"generate_recomment_node_attempt_{state['retry_count']}",
            metadata={
                "board_type": current_request.board_type,
                "post_id": current_request.post.id if current_request.post else None,
                "comment_id": current_request.comment.id if current_request.comment else None,
                "retry_attempt": state["retry_count"]
            },
            input=current_request,
            environment=self.mode
        )

        try:
            prompt = BotRecommentsPrompt()
            prompt_client, messages = prompt.json_to_messages(current_request, self.mode)
            state["messages"] = messages
            state["prompt_client"] = prompt_client

            log_model_parameters = {
                "temperature": self.model.loader.temperature,
                "top_p": self.model.loader.top_p,
                "max_tokens": self.model.loader.max_tokens,
                "stop": self.model.loader.stop,
            }
            
            # Generation 시작 시간
            start_time = datetime.now()
            model_response = self.model.get_response(
                messages, trace=node_span, start_time=start_time, prompt=prompt_client, name="generate_bot_recomment"
            )
            end_time = datetime.now()

            original_content = model_response.get("content", "")

            log_inference_to_langfuse(
                trace=node_span,
                name="generate_bot_recomment_original",
                prompt=prompt_client,
                messages=messages,
                content=original_content,
                model_name=self.model.loader.model_path,
                model_parameters=log_model_parameters,
                input_tokens=None,
                output_tokens=None,
                inference_time=(end_time - start_time).total_seconds(),
                start_time=start_time,
                end_time=end_time,
                error=None
            )

            print(f"content : {original_content}")
            print(f"inference_time : {(end_time - start_time).total_seconds()}")

            state["original_content"] = original_content
            state["error"] = ""

        except Exception as e:
            self.logger.error(f"Error generating bot recomment in node: {e}", exc_info=True)
            state["error"] = str(e)
            node_span.update(
                status="error",
                error=str(e),
                metadata={"error_type": type(e).__name__}
            )
            state["original_content"] = ""
        finally:
            node_span.end()

        return state

    async def _clean_and_evaluate_node(self, state: GraphState) -> GraphState:
        original_content = state["original_content"]
        main_trace = state["trace"]
        messages = state["messages"]
        prompt_client = state["prompt_client"]

        # 노드 실행을 위한 스팬 생성
        node_span = main_trace.span(name=f"clean_and_evaluate_node_attempt_{state['retry_count']}")
        try:
            log_model_parameters = {
                "temperature": self.model.loader.temperature,
                "top_p": self.model.loader.top_p,
                "max_tokens": self.model.loader.max_tokens,
                "stop": self.model.loader.stop,
            }

            start_time = datetime.now()
            content = self.clean_response(original_content)
            end_time = datetime.now()

            log_inference_to_langfuse(
                trace=node_span,
                name="generate_bot_recomment_cleaned",
                prompt=prompt_client,
                messages=messages,
                content=content,
                model_name=self.model.loader.model_path,
                model_parameters=log_model_parameters,
                input_tokens=None,
                output_tokens=None,
                inference_time=(end_time - start_time).total_seconds(),
                start_time=start_time,
                end_time=end_time,
                error=None
            )

            print(f"cleaned content : {content}")
            print(f"inference_time : {(end_time - start_time).total_seconds()}")

            if not content.strip():
                state["evaluation_status"] = "empty"
            else:
                state["evaluation_status"] = "success"

            state["cleaned_content"] = content
        except Exception as e:
            self.logger.error(f"Error cleaning and evaluating in node: {e}", exc_info=True)
            state["error"] = str(e)
            node_span.update(
                status="error",
                error=str(e),
                metadata={"error_type": type(e).__name__}
            )
            state["evaluation_status"] = "error"
        finally:
            node_span.end()
        return state

    async def _check_retry_conditions_node(self, state: GraphState) -> GraphState:
        state["retry_count"] += 1
        main_trace = state["trace"]
        return state

    async def generate_bot_recomments(self, request: BotRecommentsRequest) -> BotRecommentsResponse:
        """
        소셜봇 대댓글을 생성하는 서비스
        Args:
            request: BotRecommentsRequest 객체
        Returns:
            BotRecommentsResponse: 생성된 대댓글 응답
        Raises:
            InvalidQueryParameterError: 필수 필드 누락
            InvalidFormatError: 요청 필드 형식 오류
            InternalServerError: 내부 서버 오류
        """
        # 필수 필드 검증: board_type, post, comment (recomments는 Optional)
        if not request.board_type:
            raise InvalidQueryParameterError(field="board_type")
        if not request.post or not request.comment:
            raise InvalidQueryParameterError(field="body")

        # Langgraph 실행을 위한 메인 Langfuse 트레이스 시작
        main_trace = self.langfuse.trace(
            name="bot_recomments_generation_langgraph_flow",
            metadata={
                "board_type": request.board_type,
                "post_id": request.post.id if request.post else None,
                "comment_id": request.comment.id if request.comment else None,
            },
            input=request,
            environment=self.mode
        )

        initial_state: GraphState = {
            "request": request,
            "retry_count": 0,
            "original_content": "",
            "cleaned_content": "",
            "evaluation_status": "empty",
            "error": "",
            "messages": [],
            "prompt_client": None,
            "trace": main_trace
        }

        try:
            final_state = await self.app_graph.ainvoke(initial_state)

            # 최종 결과 기록 및 메인 트레이스 업데이트
            main_trace.update(output=final_state["cleaned_content"])
            if final_state["evaluation_status"] == "success":
                main_trace.update(status="success")
            else:
                main_trace.update(
                    status="error",
                    error=final_state["error"] if final_state["error"] else "Failed to generate valid recomment after retries.",
                    metadata={
                        "final_retry_count": final_state["retry_count"],
                        "final_evaluation_status": final_state["evaluation_status"]
                    }
                )

            if final_state["evaluation_status"] == "success":
                # 응답 데이터 구성
                prompt = BotRecommentsPrompt()
                bot_user = prompt.get_bot_user_info()
                data = BotRecommentResponseData(
                    board_type=request.board_type,
                    post_id=request.post.id,
                    comment_id=request.comment.id,
                    user=UserInfoResponse(**bot_user),
                    content=final_state["cleaned_content"]
                )

                return BotRecommentsResponse(
                    message="소셜봇이 대댓글을 작성했습니다.",
                    data=data
                )
            else:
                self.logger.error(f"Failed to generate valid bot recomment after multiple retries. Last error: {final_state['error']}", exc_info=True)
                raise InternalServerError(
                    detail="Failed to generate bot recomment after multiple retries."
                )

        except InvalidQueryParameterError:
            # 400 Bad Request
            if main_trace:
                main_trace.update(
                    status="error",
                    error="InvalidQueryParameterError",
                    metadata={"error_type": "InvalidQueryParameterError"}
                )
            raise
        
        except Exception as e:
            self.logger.error(f"Error during Langgraph execution: {e}", exc_info=True)
            if main_trace:
                main_trace.update(
                    status="error",
                    error=str(e),
                    metadata={"error_type": type(e).__name__}
                )
            raise InternalServerError()
